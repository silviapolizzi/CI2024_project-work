{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 10000)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def true_f(x: np.ndarray) -> np.ndarray:\n",
    "    return x[0] + np.sin(x[1]) / 5\n",
    "\n",
    "\n",
    "TEST_SIZE = 10_000\n",
    "TRAIN_SIZE = 1000\n",
    "\n",
    "x_validation = np.vstack(\n",
    "    [\n",
    "        np.random.random_sample(size=TEST_SIZE) * 2 * np.pi - np.pi,\n",
    "        np.random.random_sample(size=TEST_SIZE) * 2 - 1,\n",
    "    ]\n",
    ")\n",
    "y_validation = true_f(x_validation)\n",
    "\n",
    "print(x_validation.shape)\n",
    "print(y_validation.shape)\n",
    "train_indexes = np.random.choice(TEST_SIZE, size=TRAIN_SIZE, replace=False)\n",
    "x_train = x_validation[:, train_indexes]\n",
    "y_train = y_validation[train_indexes]\n",
    "assert np.all(y_train == true_f(x_train)), \"D'ho\"\n",
    "np.savez('problem_0.npz', x=x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num variables: 2\n",
      "Generation 0: Best fitness = 0.2567110770941986\n",
      "Generation 1: Best fitness = 0.24725834335385383\n",
      "Generation 2: Best fitness = 0.23794634599982795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silvi\\AppData\\Local\\Temp\\ipykernel_24952\\2168546716.py:13: RuntimeWarning: divide by zero encountered in divide\n",
      "  return a / b_safe\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 3: Best fitness = 0.23794634599982795\n",
      "Generation 4: Best fitness = 0.011461833062336809\n",
      "Generation 5: Best fitness = 0.05040207911046368\n",
      "Generation 6: Best fitness = 0.23794634599982795\n",
      "Generation 7: Best fitness = 0.23794634599982795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silvi\\AppData\\Local\\Temp\\ipykernel_24952\\2168546716.py:62: RuntimeWarning: invalid value encountered in add\n",
      "  return self.value(left_val, right_val)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 8: Best fitness = 0.23794634599982795\n",
      "Generation 9: Best fitness = 0.11931188383017033\n",
      "Generation 10: Best fitness = 0.23794634599982795\n",
      "Generation 11: Best fitness = 0.2985427259258043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\silvi\\AppData\\Local\\Temp\\ipykernel_24952\\2168546716.py:62: RuntimeWarning: invalid value encountered in multiply\n",
      "  return self.value(left_val, right_val)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 12: Best fitness = 0.23794634599982795\n",
      "Generation 13: Best fitness = 0.18220992979179018\n",
      "Generation 14: Best fitness = 0.009613944469277875\n",
      "Generation 15: Best fitness = 0.09796874560808513\n",
      "Generation 16: Best fitness = 0.09796874560808513\n",
      "Generation 17: Best fitness = 0.23794634599982795\n",
      "Generation 18: Best fitness = 0.23794634599982795\n",
      "Generation 19: Best fitness = 0.23787201357589355\n",
      "Generation 20: Best fitness = 0.1139944308288348\n",
      "Generation 21: Best fitness = 0.22930993656789866\n",
      "Generation 22: Best fitness = 0.35174990221643126\n",
      "Generation 23: Best fitness = 0.6332661449780216\n",
      "Generation 24: Best fitness = 0.6507392722616504\n",
      "Generation 25: Best fitness = 0.23506074832798346\n",
      "Generation 26: Best fitness = 0.21927510737125727\n",
      "Generation 27: Best fitness = 0.11191133447787266\n",
      "Generation 28: Best fitness = 0.23794634599982795\n",
      "Generation 29: Best fitness = 0.23794634599982795\n",
      "Generation 30: Best fitness = 0.08619261975442272\n",
      "Generation 31: Best fitness = 0.23794634599982795\n",
      "Generation 32: Best fitness = 0.23794634599982795\n",
      "Generation 33: Best fitness = 0.23794634599982795\n",
      "Generation 34: Best fitness = 0.23794634599982795\n",
      "Generation 35: Best fitness = 0.23794634599982795\n",
      "Generation 36: Best fitness = 0.1320286540887383\n",
      "Generation 37: Best fitness = 0.23794634599982795\n",
      "Generation 38: Best fitness = 0.23794634599982795\n",
      "Generation 39: Best fitness = 0.23794634599982795\n",
      "Generation 40: Best fitness = 0.23794634599982795\n",
      "Generation 41: Best fitness = 0.23794634599982795\n",
      "Generation 42: Best fitness = 0.4928484932935906\n",
      "Generation 43: Best fitness = 0.18635387488376096\n",
      "Generation 44: Best fitness = 0.08025564415594465\n",
      "Generation 45: Best fitness = 0.08025564415594465\n",
      "Generation 46: Best fitness = 0.11886385103371853\n",
      "Generation 47: Best fitness = 1.2721097937770016\n",
      "Generation 48: Best fitness = 0.2378311616280394\n",
      "Generation 49: Best fitness = 0.08508467904230069\n",
      "Best expression: (0 <ufunc 'add'> 1)\n",
      "Best fitness: 0.23794634599982795\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from typing import Callable\n",
    "\n",
    "# Define constants for the genetic programming algorithm\n",
    "POPULATION_SIZE = 100\n",
    "GENERATIONS = 50\n",
    "TOURNAMENT_SIZE = 5\n",
    "MUTATION_RATE = 0.2\n",
    "CROSSOVER_RATE = 0.5\n",
    "def safe_divide(a, b, eps=1e-12):\n",
    "    b_safe = np.where(np.abs(b) > eps, b, eps * np.sign(b))  # Replace zeros with small values\n",
    "    return a / b_safe\n",
    "\n",
    "\n",
    "\n",
    "def safe_log(x, eps=1e-12):\n",
    "    return np.where(x > eps, np.log(x), 0)\n",
    "\n",
    "# Define the set of allowed numpy functions\n",
    "FUNCTION_SET = [np.add, np.subtract, np.multiply, safe_divide,] #, np.exp, safe_log]\n",
    "TERMINAL_SET = []  # This will be populated dynamically with input variables\n",
    "\n",
    "# Load data from the .npz file\n",
    "def load_data(file_path: str):\n",
    "    try:\n",
    "        data = np.load(file_path)\n",
    "        x = data['x']\n",
    "        y = data['y']\n",
    "        return x, y\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error loading data from {file_path}: {e}\")\n",
    "\n",
    "# Define a node class for the genetic programming tree\n",
    "class Node:\n",
    "    def __init__(self, value, left=None, right=None):\n",
    "        self.value = value\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "    def is_operator(self):\n",
    "        return self.value in FUNCTION_SET\n",
    "\n",
    "    def is_variable(self):\n",
    "        return isinstance(self.value, int)\n",
    "\n",
    "    def is_constant(self):\n",
    "        return isinstance(self.value, float)\n",
    "\n",
    "    def evaluate(self, variables: np.ndarray):\n",
    "        try:\n",
    "            if callable(self.value):  # Function node\n",
    "                left_val = self.left.evaluate(variables) if self.left else None\n",
    "                right_val = self.right.evaluate(variables) if self.right else None\n",
    "                \n",
    "                # Handle divide-by-zero and log of non-positive values\n",
    "                if self.value == np.divide and (right_val == 0 or np.isinf(right_val)):\n",
    "                    return np.inf\n",
    "                if self.value == np.log and (left_val <= 0 or np.isinf(left_val)):\n",
    "                    return np.inf\n",
    "\n",
    "                return self.value(left_val, right_val)\n",
    "            elif isinstance(self.value, int):  # Variable index\n",
    "                if 0 <= self.value < len(variables):  # Verifica che l'indice sia valido\n",
    "                    return variables[self.value]\n",
    "                else:\n",
    "                    raise ValueError(f\"Invalid variable index {self.value} for input {variables}\")\n",
    "\n",
    "            else:  # Constant\n",
    "                return self.value\n",
    "        except:\n",
    "            return np.inf\n",
    "\n",
    "\n",
    "    def __str__(self):\n",
    "        if self.is_operator():\n",
    "            return f\"({str(self.left)} {self.value} {str(self.right)})\"\n",
    "        return str(self.value)\n",
    "\n",
    "# Generate a random tree for initial population\n",
    "def generate_random_tree(depth: int, num_variables: int, used_variables=None):\n",
    "    if used_variables is None:\n",
    "        used_variables = set()\n",
    "\n",
    "    if depth == 0 or (depth > 1 and random.random() < 0.3 and len(used_variables) == num_variables):  # 30% chance to stop at terminal\n",
    "        if random.random() < 0.5 and len(used_variables) < num_variables:  # Variable\n",
    "            var_index = random.choice([i for i in range(num_variables) if i not in used_variables])\n",
    "            used_variables.add(var_index)\n",
    "            return Node(var_index)\n",
    "        else:  # Constant\n",
    "            return Node(random.uniform(-1.0, 1.0))\n",
    "    else:\n",
    "        func = random.choice(FUNCTION_SET)\n",
    "        left = generate_random_tree(depth - 1, num_variables, used_variables)\n",
    "        right = generate_random_tree(depth - 1, num_variables, used_variables)\n",
    "        return Node(func, left, right)\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate fitness (mean squared error)\n",
    "def fitness(tree: Node, x: np.ndarray, y: np.ndarray):\n",
    "    try:\n",
    "        # print(f\"x shape: {x.shape}\")\n",
    "        # for xi in x.T:\n",
    "        #     print(\"Input xi:\", xi)\n",
    "        #     result = tree.evaluate(xi)\n",
    "        #     print(\"Tree: \", tree)\n",
    "        #     print(\"Result:\", result)\n",
    "\n",
    "        predictions = np.array([tree.evaluate(xi) for xi in x.T])\n",
    "\n",
    "        # print(f\"Predictions: {predictions}\")\n",
    "\n",
    "\n",
    "        # single_sample = x[:, 0]  # First column, shape (2,)\n",
    "        # print(\"Single sample:\", single_sample)\n",
    "        # result = tree.evaluate(single_sample)\n",
    "        \n",
    "        # print(\"Result:\", result)\n",
    "\n",
    "        # print(f\"Fitness: {np.mean((predictions - y) ** 2)}\")\n",
    "        if np.any(np.isinf(predictions)) or np.any(np.isnan(predictions)):\n",
    "            return np.inf\n",
    "        return np.mean((predictions - y) ** 2)\n",
    "    except:\n",
    "        return np.inf\n",
    "\n",
    "\n",
    "\n",
    "# Tournament selection\n",
    "def tournament_selection(population, scores):\n",
    "    tournament = random.sample(list(zip(population, scores)), TOURNAMENT_SIZE)\n",
    "    tournament.sort(key=lambda ind: ind[1])\n",
    "    return tournament[0][0]\n",
    "\n",
    "# Crossover between two parent trees\n",
    "def crossover(tree1: Node, tree2: Node):\n",
    "    if tree1.is_operator() and tree2.is_operator():\n",
    "        if random.random() < 0.5:\n",
    "            return Node(tree1.value, crossover(tree1.left, tree2.left), crossover(tree1.right, tree2.right))\n",
    "        else:\n",
    "            return Node(tree2.value, crossover(tree1.left, tree2.left), crossover(tree1.right, tree2.right))\n",
    "    elif tree1.is_operator():\n",
    "        return Node(tree1.value, crossover(tree1.left, tree2), crossover(tree1.right, tree2))\n",
    "    elif tree2.is_operator():\n",
    "        return Node(tree2.value, crossover(tree1, tree2.left), crossover(tree1, tree2.right))\n",
    "    else:\n",
    "        return tree1 if random.random() < 0.5 else tree2\n",
    "\n",
    "def validate_tree(tree: Node, num_variables: int):\n",
    "    used_variables = set()\n",
    "    def traverse(node):\n",
    "        if node.is_variable():\n",
    "            used_variables.add(node.value)\n",
    "        if node.left:\n",
    "            traverse(node.left)\n",
    "        if node.right:\n",
    "            traverse(node.right)\n",
    "    traverse(tree)\n",
    "    return len(used_variables) == num_variables\n",
    "\n",
    "\n",
    "def mutate(tree: Node, num_variables: int):\n",
    "    if random.random() < MUTATION_RATE:\n",
    "        return generate_random_tree(random.randint(1, 3), num_variables)\n",
    "    \n",
    "    if tree.is_operator():\n",
    "        if tree.left:\n",
    "            tree.left = mutate(tree.left, num_variables)\n",
    "        if tree.right:\n",
    "            tree.right = mutate(tree.right, num_variables)\n",
    "    else:\n",
    "        if tree.left:\n",
    "            tree.left = mutate(tree.left, num_variables)\n",
    "        if tree.right:\n",
    "            tree.right = mutate(tree.right, num_variables)\n",
    "    \n",
    "    return tree\n",
    "\n",
    "\n",
    "# Main genetic programming loop\n",
    "# def genetic_programming(x: np.ndarray, y: np.ndarray):\n",
    "#     num_variables = x.shape[1]\n",
    "#     TERMINAL_SET.extend(range(num_variables))\n",
    "\n",
    "#     # Initialize population\n",
    "#     population = [generate_random_tree(3, num_variables) for _ in range(POPULATION_SIZE)]\n",
    "\n",
    "#     for generation in range(GENERATIONS):\n",
    "#         scores = [fitness(ind, x, y) for ind in population]\n",
    "#         new_population = []\n",
    "\n",
    "#         while len(new_population) < POPULATION_SIZE:\n",
    "#             parent1 = tournament_selection(population, scores)\n",
    "#             parent2 = tournament_selection(population, scores)\n",
    "#             child1, child2 = crossover(parent1, parent2)\n",
    "#             child1 = mutate(child1, num_variables)\n",
    "#             child2 = mutate(child2, num_variables)\n",
    "#             new_population.extend([child1, child2])\n",
    "\n",
    "#         population = new_population[:POPULATION_SIZE]\n",
    "\n",
    "#         # **Population diversity check**\n",
    "#         if len(set(str(ind) for ind in population)) < POPULATION_SIZE // 2:\n",
    "#             # Reintroduce random individuals to increase diversity\n",
    "#             population.extend([generate_random_tree(3, num_variables) for _ in range(POPULATION_SIZE // 2)])\n",
    "#             population = population[:POPULATION_SIZE]  # Ensure population size remains constant\n",
    "\n",
    "#         # Print best fitness of the generation\n",
    "#         best_score = min(scores)\n",
    "#         print(f\"Generation {generation}: Best fitness = {best_score}\")\n",
    "\n",
    "\n",
    "\n",
    "#     scores = [fitness(ind, x, y) for ind in population]  # Recalculate scores for the final population\n",
    "#     best_index = scores.index(min(scores))\n",
    "\n",
    "    \n",
    "#     return population[best_index]\n",
    "def genetic_programming(x: np.ndarray, y: np.ndarray):\n",
    "    num_variables = x.shape[0]\n",
    "    print(\"Num variables:\", num_variables)\n",
    "\n",
    "    # Initialize population\n",
    "    population = [generate_random_tree(3, num_variables) for _ in range(POPULATION_SIZE)]\n",
    "\n",
    "    for generation in range(GENERATIONS):\n",
    "        scores = [fitness(ind, x, y) for ind in population]\n",
    "        new_population = []\n",
    "\n",
    "        while len(new_population) < POPULATION_SIZE:\n",
    "            parent1 = tournament_selection(population, scores)\n",
    "            parent2 = tournament_selection(population, scores)\n",
    "            child1 = crossover(parent1, parent2)\n",
    "            child2 = crossover(parent1, parent2)\n",
    "            child1 = mutate(child1, num_variables)\n",
    "            child2 = mutate(child2, num_variables)\n",
    "            if validate_tree(child1, num_variables):\n",
    "                new_population.append(child1)\n",
    "            if validate_tree(child2, num_variables):\n",
    "                new_population.append(child2)\n",
    "\n",
    "        population = new_population[:POPULATION_SIZE]\n",
    "\n",
    "        # Population diversity check\n",
    "        if len(set(str(ind) for ind in population)) < POPULATION_SIZE // 2:\n",
    "            print(\"Low diversity in population, consider introducing new random individuals.\")\n",
    "            population.extend([generate_random_tree(3, num_variables) for _ in range(POPULATION_SIZE // 2)])\n",
    "            population = population[:POPULATION_SIZE]  # Ensure population size remains constant\n",
    "\n",
    "        # Print best fitness of the generation\n",
    "        best_score = min(scores)\n",
    "        print(f\"Generation {generation}: Best fitness = {best_score}\")\n",
    "\n",
    "    scores = [fitness(ind, x, y) for ind in population]  # Recalculate scores for the final population\n",
    "    best_index = scores.index(min(scores))\n",
    "    return population[best_index]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the data\n",
    "    x, y = load_data(\"problem_0.npz\")\n",
    "\n",
    "    # Run genetic programming\n",
    "    best_tree = genetic_programming(x, y)\n",
    "\n",
    "    # Output the best tree and its fitness\n",
    "    print(\"Best expression:\", best_tree)\n",
    "    print(\"Best fitness:\", fitness(best_tree, x, y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
